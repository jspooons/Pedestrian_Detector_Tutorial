{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# TorchVision Object Detection Finetuning Tutorial"
      ],
      "metadata": {
        "id": "tDfRY5gbEt2w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1) Initial Installs"
      ],
      "metadata": {
        "id": "OnU_rIpEHI7d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.system(\"wget https://raw.githubusercontent.com/pytorch/vision/main/references/detection/engine.py\")\n",
        "os.system(\"wget https://raw.githubusercontent.com/pytorch/vision/main/references/detection/utils.py\")\n",
        "os.system(\"wget https://raw.githubusercontent.com/pytorch/vision/main/references/detection/coco_utils.py\")\n",
        "os.system(\"wget https://raw.githubusercontent.com/pytorch/vision/main/references/detection/coco_eval.py\")\n",
        "os.system(\"wget https://raw.githubusercontent.com/pytorch/vision/main/references/detection/transforms.py\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V-VCM2oIHFWA",
        "outputId": "8347d01c-fd6c-43b5-92f7-15ed21048b55"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2) Imports"
      ],
      "metadata": {
        "id": "L-f_rkHGFNEq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import utils\n",
        "\n",
        "import zipfile\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from engine import train_one_epoch, evaluate\n",
        "\n",
        "from torchvision import tv_tensors\n",
        "from torchvision.io import read_image\n",
        "from torchvision.utils import draw_bounding_boxes, draw_segmentation_masks\n",
        "from torchvision.transforms import v2 as T\n",
        "from torchvision.ops.boxes import masks_to_boxes\n",
        "from torchvision.transforms.v2 import functional as F\n",
        "from torchvision.models.detection import FasterRCNN\n",
        "from torchvision.models.detection.rpn import AnchorGenerator\n",
        "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor"
      ],
      "metadata": {
        "id": "nN1l7OeYFHw0"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3) Defining the Dataset"
      ],
      "metadata": {
        "id": "TMY1QVtPE2zb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will be importing the Penn-Fudan Database for Pedestrian Detection and Segmentation.\n",
        "\n",
        "It contains 170 images with 345 instances of pedestrians. The file structure of the dataset is as follows:\n",
        "\n",
        "```\n",
        "- PennFudanPed/\n",
        "  - PedMasks/\n",
        "    - FudanPed00001_mask.png\n",
        "    - ...\n",
        "  - PNGImages/\n",
        "    - FudanPed00001.png\n",
        "    - ...\n",
        "\n",
        "```\n",
        "\n",
        "We will create a new torchvision dataset to compile the masks and images of pedestrians together into feature vectors with an associated label.\n",
        "\n",
        "The `torch.utils.data.Dataset` class should implement the `__len__` and `__getitem__` methods. The only requirement is that `__getitem__` returns a tuple of (image, target)\n",
        "\n",
        "- image: `torchvision.tv_tensors.Image` of shape [3, H, W], a pure tensor, or a PIL Image of size (H, W)\n",
        "- target: a dict containing\n",
        "  - **boxes**, `torchvision.tv_tensors.BoundingBoxes` of shape **[N, 4]**, the coordinates of the **N** bounding boxes in **[x0, y0, x1, y1]** format, randing from **0** to **W**, and **0** to **H**\n",
        "  - **labels**, integer `torch.Tensor` of shape **[N]**: the label for each bounding box. **0** represents always the background class.\n",
        "  - **image_id**, int: an image identifier\n",
        "  - **area**, float `torch.Tensor` of shape **[N]**: the area of the bounding box. This is used during evaluation with the COCO metric, to separate the metric scores between small, medium and large boxes.\n",
        "  - **iscrowd**, uint8 `torch.Tensor` of shape **[N]**: instances with `iscrowd=True` will be ignored suring evaluation\n",
        "  - (optionally) **masks**, `torchvision.tv_tensors.Mask of shape **[N, H, W]**: the segmentation masks for each of the objects\n",
        "\n",
        "One note on the **labels**, the model considers **0** as background. If your dataset does not contain the background class, you should not have **0** in your **labels**. For example, if you have two classes, they should be represented as **1** or **2**."
      ],
      "metadata": {
        "id": "KJvCOhVhI43r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://www.cis.upenn.edu/~jshi/ped_html/PennFudanPed.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NQfBAomFI38i",
        "outputId": "73a08f6b-4f96-4012-b75f-eca65d1c2cda"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-12-03 00:58:39--  https://www.cis.upenn.edu/~jshi/ped_html/PennFudanPed.zip\n",
            "Resolving www.cis.upenn.edu (www.cis.upenn.edu)... 158.130.69.163, 2607:f470:8:64:5ea5::d\n",
            "Connecting to www.cis.upenn.edu (www.cis.upenn.edu)|158.130.69.163|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 53723336 (51M) [application/zip]\n",
            "Saving to: ‘PennFudanPed.zip.1’\n",
            "\n",
            "PennFudanPed.zip.1  100%[===================>]  51.23M  8.73MB/s    in 7.4s    \n",
            "\n",
            "2023-12-03 00:58:47 (6.90 MB/s) - ‘PennFudanPed.zip.1’ saved [53723336/53723336]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "zip_ref = zipfile.ZipFile(\"PennFudanPed.zip\", \"r\")\n",
        "zip_ref.extractall()\n",
        "\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "_I-tSpic4JtF"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PennFudanDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, root, transforms):\n",
        "    self.root = root\n",
        "    self.transforms = transforms\n",
        "\n",
        "    # load all image files, sorting them to ensure that they are aligned\n",
        "    # so image1.png is aligned with mask1.png\n",
        "    self.imgs = list(sorted(os.listdir(os.path.join(root, \"PNGImages\"))))\n",
        "    self.masks = list(sorted(os.listdir(os.path.join(root, \"PedMasks\"))))\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    # load images and masks\n",
        "    img_path = os.path.join(self.root, \"PNGImages\", self.imgs[idx])\n",
        "    mask_path = os.path.join(self.root, \"PedMasks\", self.masks[idx])\n",
        "    img = read_image(img_path)\n",
        "    mask = read_image(mask_path)\n",
        "\n",
        "    # instances are encoded as different colours\n",
        "    obj_ids = torch.unique(mask)\n",
        "\n",
        "    # first id is the background, so remove it\n",
        "    obj_ids = obj_ids[1:]\n",
        "    num_objs = len(obj_ids)\n",
        "\n",
        "    # split the colour-encoded mask into a set of binary masks\n",
        "    masks = (mask == obj_ids[:, None, None]).to(dtype=torch.uint8)\n",
        "\n",
        "    # get bounding box coordinates for each mask\n",
        "    boxes = masks_to_boxes(masks)\n",
        "\n",
        "    # there is only one class\n",
        "    labels = torch.ones((num_objs,), dtype=torch.int64)\n",
        "\n",
        "    area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
        "\n",
        "    # suppose all instances are not crowd\n",
        "    iscrowd = torch.zeros((num_objs,), dtype=torch.int64)\n",
        "\n",
        "    # wrap sample and targets into torchvision tv_tensors:\n",
        "    img = tv_tensors.Image(img)\n",
        "\n",
        "    target = {}\n",
        "    target[\"boxes\"] = tv_tensors.BoundingBoxes(boxes, format=\"XYXY\", canvas_size=F.get_size(img))\n",
        "    target[\"masks\"] = tv_tensors.Mask(masks)\n",
        "    target[\"labels\"] = labels\n",
        "    target[\"image_id\"] = idx\n",
        "    target[\"area\"] = area\n",
        "    target[\"iscrowd\"] = iscrowd\n",
        "\n",
        "    if self.transforms is not None:\n",
        "        img, target = self.transforms(img, target)\n",
        "\n",
        "    return img, target\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.imgs)\n"
      ],
      "metadata": {
        "id": "6sIUQdpr4zA8"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4) Defining your Model\n",
        "\n",
        "We will be using Mask R-CNN, which is based on top of Faster R-CNN. Faster R-CNN is a model that predicts both bounding boxes and class scores for potential objects in the image.\n",
        "\n",
        "Mask R-CNN adds an extra branch into Faster R-CNN, which also predicts segmentation masks for each instance."
      ],
      "metadata": {
        "id": "_olPLSiy_p7L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4 a) Object Detection and Instance Segmentation model for PennFudan Dataset\n",
        "\n",
        "There are two common situation one ight want to modify one of the available models in TorchVision Model Zoo. The first is when we want to start from a pre-trained model, and just finetune the last layer. The other is when we want to replace the backbone of the model with a different one (i.e. for faster predictions).\n",
        "\n",
        "In our case, we want to finetune from a pre-trained model, given that our dataset is very small. Here we want to also compute the instance segmentation masks, so we will be using Mask R-CNN:\n",
        "\n"
      ],
      "metadata": {
        "id": "EPxg7W1oAERC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model_instance_segmentation(num_classes):\n",
        "  # load an instance segmentation model pre-trained on COCO\n",
        "  model = torchvision.models.detection.maskrcnn_resnet50_fpn(weights=\"DEFAULT\")\n",
        "\n",
        "  # get number of input features for the classifier\n",
        "  in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "\n",
        "  # replace the pre-trained head with a new one\n",
        "  model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
        "\n",
        "  # now get the number of input features for the mask classifier\n",
        "  in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels\n",
        "  hidden_layer = 256\n",
        "\n",
        "  # and replace the mask predictor with a new one\n",
        "  model.roi_heads.mask_predictor = MaskRCNNPredictor(\n",
        "      in_features_mask,\n",
        "      hidden_layer,\n",
        "      num_classes,\n",
        "  )\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "MVpqWIwd8pPd"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4 b) Helper Functions for Data Augmentation / Transformation"
      ],
      "metadata": {
        "id": "CIWExqvGGMhr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_transform(train):\n",
        "  transformations = []\n",
        "  if train:\n",
        "    transformations.append(T.RandomHorizontalFlip(0.5))\n",
        "\n",
        "  transformations.append(T.ToDtype(torch.float, scale=True))\n",
        "  transformations.append(T.ToPureTensor())\n",
        "\n",
        "  return T.Compose(transformations)"
      ],
      "metadata": {
        "id": "dok2mtDwDlqV"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4 c) Testing `forward()` method"
      ],
      "metadata": {
        "id": "YLpaUKA6GuB_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(weights=\"DEFAULT\")\n",
        "dataset = PennFudanDataset('PennFudanPed', get_transform(train=True))\n",
        "data_loader = torch.utils.data.DataLoader(\n",
        "    dataset,\n",
        "    batch_size=2,\n",
        "    shuffle=True,\n",
        "    num_workers=4,\n",
        "    collate_fn=utils.collate_fn\n",
        ")\n",
        "\n",
        "# For Training\n",
        "images, targets = next(iter(data_loader))\n",
        "images = list(image for image in images)\n",
        "targets = [{k: v for k, v in t.items()} for t in targets]\n",
        "output = model(images, targets)  # Returns losses and detections\n",
        "print(output)\n",
        "\n",
        "# For inference\n",
        "model.eval()\n",
        "x = [torch.rand(3, 300, 400), torch.rand(3, 500, 400)]\n",
        "predictions = model(x)  # Returns predictions\n",
        "print(predictions[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "idkwunPqGnMJ",
        "outputId": "30f93f51-730d-41df-9c61-6206e2595a1e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\" to /root/.cache/torch/hub/checkpoints/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\n",
            "100%|██████████| 160M/160M [00:02<00:00, 73.3MB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss_classifier': tensor(0.2052, grad_fn=<NllLossBackward0>), 'loss_box_reg': tensor(0.0504, grad_fn=<DivBackward0>), 'loss_objectness': tensor(0.0137, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'loss_rpn_box_reg': tensor(0.0037, grad_fn=<DivBackward0>)}\n",
            "{'boxes': tensor([], size=(0, 4), grad_fn=<StackBackward0>), 'labels': tensor([], dtype=torch.int64), 'scores': tensor([], grad_fn=<IndexBackward0>)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4 d) Main Code for Training and Validation"
      ],
      "metadata": {
        "id": "dhciGRRfH7fH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train on the GPU or on the CPU, if a GPU is not available\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "# our dataset has two classes only - background and person\n",
        "num_classes = 2\n",
        "\n",
        "# use our dataset and defined transformations\n",
        "dataset = PennFudanDataset('PennFudanPed', get_transform(train=True))\n",
        "dataset_test = PennFudanDataset('PennFudanPed', get_transform(train=False))\n",
        "\n",
        "# split the dataset in train and test set\n",
        "indices = torch.randperm(len(dataset)).tolist()\n",
        "dataset = torch.utils.data.Subset(dataset, indices[:-50])\n",
        "dataset_test = torch.utils.data.Subset(dataset_test, indices[-50:])\n",
        "\n",
        "# define training and validation data loaders\n",
        "data_loader = torch.utils.data.DataLoader(\n",
        "    dataset,\n",
        "    batch_size=2,\n",
        "    shuffle=True,\n",
        "    num_workers=4,\n",
        "    collate_fn=utils.collate_fn\n",
        ")\n",
        "\n",
        "data_loader_test = torch.utils.data.DataLoader(\n",
        "    dataset_test,\n",
        "    batch_size=1,\n",
        "    shuffle=False,\n",
        "    num_workers=4,\n",
        "    collate_fn=utils.collate_fn\n",
        ")\n",
        "\n",
        "# get the model using our helper function\n",
        "model = get_model_instance_segmentation(num_classes)\n",
        "\n",
        "# move model to the right device\n",
        "model.to(device)\n",
        "\n",
        "# # Freeze all layers of the pre-trained model\n",
        "# for param in model.parameters():\n",
        "#     param.requires_grad = False\n",
        "\n",
        "# # Unfreeze the new predictors for training\n",
        "# for param in model.roi_heads.box_predictor.parameters():\n",
        "#     param.requires_grad = True\n",
        "# for param in model.roi_heads.mask_predictor.parameters():\n",
        "#     param.requires_grad = True\n",
        "\n",
        "# construct an optimizer\n",
        "params = [p for p in model.parameters() if p.requires_grad]\n",
        "optimizer = torch.optim.SGD(\n",
        "    params,\n",
        "    lr=0.005,\n",
        "    momentum=0.9,\n",
        "    weight_decay=0.0005\n",
        ")\n",
        "\n",
        "# and a learning rate scheduler\n",
        "lr_scheduler = torch.optim.lr_scheduler.StepLR(\n",
        "    optimizer,\n",
        "    step_size=3,\n",
        "    gamma=0.1\n",
        ")\n",
        "\n",
        "# let's train it for 5 epochs\n",
        "num_epochs = 5\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    # train for one epoch, printing every 10 iterations\n",
        "    train_one_epoch(model, optimizer, data_loader, device, epoch, print_freq=10)\n",
        "    # update the learning rate\n",
        "    lr_scheduler.step()\n",
        "    # evaluate on the test dataset\n",
        "    evaluate(model, data_loader_test, device=device)\n",
        "\n",
        "print(\"That's it!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6u4s5RK2GvG1",
        "outputId": "46c08279-8bd8-40a6-d195-8c6c0aad451c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [0]  [ 0/60]  eta: 0:01:06  lr: 0.000090  loss: 5.1475 (5.1475)  loss_classifier: 0.8084 (0.8084)  loss_box_reg: 0.5890 (0.5890)  loss_mask: 3.7111 (3.7111)  loss_objectness: 0.0354 (0.0354)  loss_rpn_box_reg: 0.0036 (0.0036)  time: 1.1109  data: 0.3266  max mem: 2342\n",
            "Epoch: [0]  [10/60]  eta: 0:00:30  lr: 0.000936  loss: 1.6747 (2.6721)  loss_classifier: 0.4984 (0.4828)  loss_box_reg: 0.3621 (0.3583)  loss_mask: 0.9283 (1.8068)  loss_objectness: 0.0184 (0.0190)  loss_rpn_box_reg: 0.0036 (0.0051)  time: 0.6120  data: 0.0391  max mem: 3031\n",
            "Epoch: [0]  [20/60]  eta: 0:00:23  lr: 0.001783  loss: 0.9949 (1.7501)  loss_classifier: 0.2499 (0.3298)  loss_box_reg: 0.2410 (0.3021)  loss_mask: 0.3865 (1.0906)  loss_objectness: 0.0169 (0.0200)  loss_rpn_box_reg: 0.0053 (0.0076)  time: 0.5638  data: 0.0093  max mem: 3031\n",
            "Epoch: [0]  [30/60]  eta: 0:00:17  lr: 0.002629  loss: 0.5846 (1.3581)  loss_classifier: 0.1010 (0.2579)  loss_box_reg: 0.1573 (0.2717)  loss_mask: 0.2435 (0.8054)  loss_objectness: 0.0088 (0.0155)  loss_rpn_box_reg: 0.0062 (0.0076)  time: 0.5601  data: 0.0098  max mem: 3031\n",
            "Epoch: [0]  [40/60]  eta: 0:00:11  lr: 0.003476  loss: 0.4972 (1.1524)  loss_classifier: 0.0748 (0.2135)  loss_box_reg: 0.2052 (0.2619)  loss_mask: 0.1862 (0.6558)  loss_objectness: 0.0052 (0.0133)  loss_rpn_box_reg: 0.0069 (0.0079)  time: 0.5488  data: 0.0114  max mem: 3031\n",
            "Epoch: [0]  [50/60]  eta: 0:00:05  lr: 0.004323  loss: 0.4598 (1.0117)  loss_classifier: 0.0662 (0.1827)  loss_box_reg: 0.2052 (0.2507)  loss_mask: 0.1627 (0.5595)  loss_objectness: 0.0035 (0.0115)  loss_rpn_box_reg: 0.0054 (0.0073)  time: 0.5521  data: 0.0105  max mem: 3031\n",
            "Epoch: [0]  [59/60]  eta: 0:00:00  lr: 0.005000  loss: 0.4224 (0.9120)  loss_classifier: 0.0470 (0.1608)  loss_box_reg: 0.1825 (0.2344)  loss_mask: 0.1538 (0.4996)  loss_objectness: 0.0022 (0.0103)  loss_rpn_box_reg: 0.0046 (0.0070)  time: 0.5675  data: 0.0089  max mem: 3094\n",
            "Epoch: [0] Total time: 0:00:34 (0.5747 s / it)\n",
            "creating index...\n",
            "index created!\n",
            "Test:  [ 0/50]  eta: 0:00:27  model_time: 0.2500 (0.2500)  evaluator_time: 0.0117 (0.0117)  time: 0.5448  data: 0.2816  max mem: 3094\n",
            "Test:  [49/50]  eta: 0:00:00  model_time: 0.1302 (0.1349)  evaluator_time: 0.0133 (0.0148)  time: 0.1630  data: 0.0047  max mem: 3094\n",
            "Test: Total time: 0:00:08 (0.1691 s / it)\n",
            "Averaged stats: model_time: 0.1302 (0.1349)  evaluator_time: 0.0133 (0.0148)\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.635\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.980\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.822\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.328\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.548\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.652\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.279\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.699\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.699\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.500\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.693\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.705\n",
            "IoU metric: segm\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.692\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.980\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.899\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.325\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.443\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.712\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.295\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.751\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.756\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.633\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.714\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.764\n",
            "Epoch: [1]  [ 0/60]  eta: 0:01:13  lr: 0.005000  loss: 0.3499 (0.3499)  loss_classifier: 0.0567 (0.0567)  loss_box_reg: 0.1009 (0.1009)  loss_mask: 0.1830 (0.1830)  loss_objectness: 0.0015 (0.0015)  loss_rpn_box_reg: 0.0078 (0.0078)  time: 1.2182  data: 0.5175  max mem: 3094\n",
            "Epoch: [1]  [10/60]  eta: 0:00:30  lr: 0.005000  loss: 0.2377 (0.2806)  loss_classifier: 0.0226 (0.0306)  loss_box_reg: 0.0672 (0.1006)  loss_mask: 0.1298 (0.1412)  loss_objectness: 0.0006 (0.0012)  loss_rpn_box_reg: 0.0071 (0.0070)  time: 0.6084  data: 0.0544  max mem: 3094\n",
            "Epoch: [1]  [20/60]  eta: 0:00:23  lr: 0.005000  loss: 0.2381 (0.2969)  loss_classifier: 0.0261 (0.0372)  loss_box_reg: 0.0802 (0.1047)  loss_mask: 0.1239 (0.1460)  loss_objectness: 0.0007 (0.0015)  loss_rpn_box_reg: 0.0068 (0.0074)  time: 0.5632  data: 0.0085  max mem: 3117\n",
            "Epoch: [1]  [30/60]  eta: 0:00:17  lr: 0.005000  loss: 0.2605 (0.3094)  loss_classifier: 0.0368 (0.0392)  loss_box_reg: 0.0911 (0.1056)  loss_mask: 0.1345 (0.1558)  loss_objectness: 0.0009 (0.0016)  loss_rpn_box_reg: 0.0054 (0.0072)  time: 0.5689  data: 0.0091  max mem: 3117\n",
            "Epoch: [1]  [40/60]  eta: 0:00:11  lr: 0.005000  loss: 0.3093 (0.3108)  loss_classifier: 0.0401 (0.0400)  loss_box_reg: 0.0941 (0.1022)  loss_mask: 0.1654 (0.1596)  loss_objectness: 0.0010 (0.0016)  loss_rpn_box_reg: 0.0054 (0.0073)  time: 0.5767  data: 0.0091  max mem: 3409\n",
            "Epoch: [1]  [50/60]  eta: 0:00:05  lr: 0.005000  loss: 0.2935 (0.3071)  loss_classifier: 0.0433 (0.0408)  loss_box_reg: 0.0862 (0.0981)  loss_mask: 0.1587 (0.1592)  loss_objectness: 0.0012 (0.0018)  loss_rpn_box_reg: 0.0040 (0.0072)  time: 0.5785  data: 0.0100  max mem: 3409\n",
            "Epoch: [1]  [59/60]  eta: 0:00:00  lr: 0.005000  loss: 0.2466 (0.2988)  loss_classifier: 0.0363 (0.0391)  loss_box_reg: 0.0686 (0.0931)  loss_mask: 0.1343 (0.1582)  loss_objectness: 0.0009 (0.0017)  loss_rpn_box_reg: 0.0034 (0.0067)  time: 0.5344  data: 0.0092  max mem: 3409\n",
            "Epoch: [1] Total time: 0:00:34 (0.5733 s / it)\n",
            "creating index...\n",
            "index created!\n",
            "Test:  [ 0/50]  eta: 0:00:25  model_time: 0.2337 (0.2337)  evaluator_time: 0.0066 (0.0066)  time: 0.5098  data: 0.2682  max mem: 3409\n",
            "Test:  [49/50]  eta: 0:00:00  model_time: 0.1303 (0.1315)  evaluator_time: 0.0041 (0.0084)  time: 0.1472  data: 0.0074  max mem: 3409\n",
            "Test: Total time: 0:00:07 (0.1583 s / it)\n",
            "Averaged stats: model_time: 0.1303 (0.1315)  evaluator_time: 0.0041 (0.0084)\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.711\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.980\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.885\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.373\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.557\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.735\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.318\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.757\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.760\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.533\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.671\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.777\n",
            "IoU metric: segm\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.753\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.980\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.942\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.368\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.545\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.778\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.320\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.791\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.791\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.600\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.707\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.807\n",
            "Epoch: [2]  [ 0/60]  eta: 0:01:00  lr: 0.005000  loss: 0.2720 (0.2720)  loss_classifier: 0.0455 (0.0455)  loss_box_reg: 0.0771 (0.0771)  loss_mask: 0.1451 (0.1451)  loss_objectness: 0.0006 (0.0006)  loss_rpn_box_reg: 0.0036 (0.0036)  time: 1.0079  data: 0.3842  max mem: 3409\n",
            "Epoch: [2]  [10/60]  eta: 0:00:28  lr: 0.005000  loss: 0.2267 (0.2321)  loss_classifier: 0.0275 (0.0306)  loss_box_reg: 0.0568 (0.0559)  loss_mask: 0.1290 (0.1407)  loss_objectness: 0.0008 (0.0018)  loss_rpn_box_reg: 0.0029 (0.0031)  time: 0.5697  data: 0.0417  max mem: 3409\n",
            "Epoch: [2]  [20/60]  eta: 0:00:22  lr: 0.005000  loss: 0.2180 (0.2304)  loss_classifier: 0.0275 (0.0304)  loss_box_reg: 0.0496 (0.0548)  loss_mask: 0.1409 (0.1394)  loss_objectness: 0.0009 (0.0016)  loss_rpn_box_reg: 0.0030 (0.0041)  time: 0.5461  data: 0.0105  max mem: 3409\n",
            "Epoch: [2]  [30/60]  eta: 0:00:17  lr: 0.005000  loss: 0.2377 (0.2450)  loss_classifier: 0.0297 (0.0337)  loss_box_reg: 0.0596 (0.0637)  loss_mask: 0.1435 (0.1411)  loss_objectness: 0.0013 (0.0019)  loss_rpn_box_reg: 0.0047 (0.0047)  time: 0.5717  data: 0.0114  max mem: 3409\n",
            "Epoch: [2]  [40/60]  eta: 0:00:11  lr: 0.005000  loss: 0.2377 (0.2461)  loss_classifier: 0.0372 (0.0342)  loss_box_reg: 0.0677 (0.0642)  loss_mask: 0.1353 (0.1408)  loss_objectness: 0.0009 (0.0019)  loss_rpn_box_reg: 0.0055 (0.0050)  time: 0.5738  data: 0.0091  max mem: 3409\n",
            "Epoch: [2]  [50/60]  eta: 0:00:05  lr: 0.005000  loss: 0.2034 (0.2377)  loss_classifier: 0.0265 (0.0325)  loss_box_reg: 0.0400 (0.0613)  loss_mask: 0.1252 (0.1375)  loss_objectness: 0.0004 (0.0018)  loss_rpn_box_reg: 0.0029 (0.0046)  time: 0.5635  data: 0.0104  max mem: 3409\n",
            "Epoch: [2]  [59/60]  eta: 0:00:00  lr: 0.005000  loss: 0.2034 (0.2362)  loss_classifier: 0.0290 (0.0324)  loss_box_reg: 0.0395 (0.0611)  loss_mask: 0.1252 (0.1366)  loss_objectness: 0.0003 (0.0016)  loss_rpn_box_reg: 0.0031 (0.0046)  time: 0.5869  data: 0.0102  max mem: 3409\n",
            "Epoch: [2] Total time: 0:00:34 (0.5775 s / it)\n",
            "creating index...\n",
            "index created!\n",
            "Test:  [ 0/50]  eta: 0:00:39  model_time: 0.2987 (0.2987)  evaluator_time: 0.0083 (0.0083)  time: 0.7828  data: 0.4739  max mem: 3409\n",
            "Test:  [49/50]  eta: 0:00:00  model_time: 0.1101 (0.1239)  evaluator_time: 0.0035 (0.0059)  time: 0.1239  data: 0.0036  max mem: 3409\n",
            "Test: Total time: 0:00:07 (0.1496 s / it)\n",
            "Averaged stats: model_time: 0.1101 (0.1239)  evaluator_time: 0.0035 (0.0059)\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.806\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.985\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.950\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.398\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.624\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.832\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.349\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.847\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.847\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.500\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.750\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.868\n",
            "IoU metric: segm\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.782\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.985\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.948\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.428\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.486\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.803\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.326\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.816\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.816\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.600\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.750\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.829\n",
            "Epoch: [3]  [ 0/60]  eta: 0:00:52  lr: 0.000500  loss: 0.1622 (0.1622)  loss_classifier: 0.0284 (0.0284)  loss_box_reg: 0.0234 (0.0234)  loss_mask: 0.1089 (0.1089)  loss_objectness: 0.0003 (0.0003)  loss_rpn_box_reg: 0.0012 (0.0012)  time: 0.8705  data: 0.4010  max mem: 3409\n",
            "Epoch: [3]  [10/60]  eta: 0:00:28  lr: 0.000500  loss: 0.1622 (0.1715)  loss_classifier: 0.0175 (0.0208)  loss_box_reg: 0.0264 (0.0336)  loss_mask: 0.1089 (0.1147)  loss_objectness: 0.0004 (0.0004)  loss_rpn_box_reg: 0.0016 (0.0021)  time: 0.5652  data: 0.0441  max mem: 3409\n",
            "Epoch: [3]  [20/60]  eta: 0:00:22  lr: 0.000500  loss: 0.1630 (0.1816)  loss_classifier: 0.0217 (0.0251)  loss_box_reg: 0.0274 (0.0353)  loss_mask: 0.1133 (0.1178)  loss_objectness: 0.0004 (0.0008)  loss_rpn_box_reg: 0.0021 (0.0027)  time: 0.5584  data: 0.0095  max mem: 3409\n",
            "Epoch: [3]  [30/60]  eta: 0:00:17  lr: 0.000500  loss: 0.1720 (0.1830)  loss_classifier: 0.0277 (0.0264)  loss_box_reg: 0.0332 (0.0364)  loss_mask: 0.1135 (0.1166)  loss_objectness: 0.0004 (0.0009)  loss_rpn_box_reg: 0.0026 (0.0027)  time: 0.5834  data: 0.0093  max mem: 3409\n",
            "Epoch: [3]  [40/60]  eta: 0:00:11  lr: 0.000500  loss: 0.1853 (0.1860)  loss_classifier: 0.0256 (0.0263)  loss_box_reg: 0.0363 (0.0376)  loss_mask: 0.1135 (0.1186)  loss_objectness: 0.0003 (0.0008)  loss_rpn_box_reg: 0.0024 (0.0027)  time: 0.5671  data: 0.0100  max mem: 3409\n",
            "Epoch: [3]  [50/60]  eta: 0:00:05  lr: 0.000500  loss: 0.1836 (0.1907)  loss_classifier: 0.0270 (0.0270)  loss_box_reg: 0.0363 (0.0405)  loss_mask: 0.1052 (0.1193)  loss_objectness: 0.0003 (0.0009)  loss_rpn_box_reg: 0.0026 (0.0030)  time: 0.5413  data: 0.0099  max mem: 3409\n",
            "Epoch: [3]  [59/60]  eta: 0:00:00  lr: 0.000500  loss: 0.1836 (0.1940)  loss_classifier: 0.0309 (0.0280)  loss_box_reg: 0.0465 (0.0423)  loss_mask: 0.1086 (0.1196)  loss_objectness: 0.0004 (0.0009)  loss_rpn_box_reg: 0.0038 (0.0032)  time: 0.5712  data: 0.0077  max mem: 3409\n",
            "Epoch: [3] Total time: 0:00:34 (0.5756 s / it)\n",
            "creating index...\n",
            "index created!\n",
            "Test:  [ 0/50]  eta: 0:00:25  model_time: 0.2184 (0.2184)  evaluator_time: 0.0050 (0.0050)  time: 0.5164  data: 0.2915  max mem: 3409\n",
            "Test:  [49/50]  eta: 0:00:00  model_time: 0.1115 (0.1199)  evaluator_time: 0.0035 (0.0052)  time: 0.1255  data: 0.0039  max mem: 3409\n",
            "Test: Total time: 0:00:07 (0.1408 s / it)\n",
            "Averaged stats: model_time: 0.1115 (0.1199)  evaluator_time: 0.0035 (0.0052)\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.819\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.985\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.950\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.398\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.626\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.847\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.356\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.859\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.859\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.500\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.750\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.882\n",
            "IoU metric: segm\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.792\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.985\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.956\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.428\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.512\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.813\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.331\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.826\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.826\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.600\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.779\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.838\n",
            "Epoch: [4]  [ 0/60]  eta: 0:00:59  lr: 0.000500  loss: 0.1766 (0.1766)  loss_classifier: 0.0186 (0.0186)  loss_box_reg: 0.0241 (0.0241)  loss_mask: 0.1315 (0.1315)  loss_objectness: 0.0001 (0.0001)  loss_rpn_box_reg: 0.0023 (0.0023)  time: 0.9898  data: 0.3963  max mem: 3409\n",
            "Epoch: [4]  [10/60]  eta: 0:00:31  lr: 0.000500  loss: 0.1803 (0.2021)  loss_classifier: 0.0269 (0.0308)  loss_box_reg: 0.0383 (0.0479)  loss_mask: 0.1124 (0.1186)  loss_objectness: 0.0007 (0.0008)  loss_rpn_box_reg: 0.0029 (0.0039)  time: 0.6325  data: 0.0473  max mem: 3409\n",
            "Epoch: [4]  [20/60]  eta: 0:00:22  lr: 0.000500  loss: 0.1652 (0.1798)  loss_classifier: 0.0232 (0.0247)  loss_box_reg: 0.0315 (0.0361)  loss_mask: 0.1095 (0.1157)  loss_objectness: 0.0004 (0.0007)  loss_rpn_box_reg: 0.0015 (0.0026)  time: 0.5502  data: 0.0101  max mem: 3409\n",
            "Epoch: [4]  [30/60]  eta: 0:00:16  lr: 0.000500  loss: 0.1523 (0.1764)  loss_classifier: 0.0190 (0.0240)  loss_box_reg: 0.0271 (0.0349)  loss_mask: 0.1056 (0.1146)  loss_objectness: 0.0002 (0.0005)  loss_rpn_box_reg: 0.0012 (0.0024)  time: 0.5263  data: 0.0090  max mem: 3409\n",
            "Epoch: [4]  [40/60]  eta: 0:00:11  lr: 0.000500  loss: 0.1815 (0.1824)  loss_classifier: 0.0243 (0.0259)  loss_box_reg: 0.0293 (0.0370)  loss_mask: 0.1067 (0.1159)  loss_objectness: 0.0002 (0.0007)  loss_rpn_box_reg: 0.0017 (0.0027)  time: 0.5746  data: 0.0106  max mem: 3409\n",
            "Epoch: [4]  [50/60]  eta: 0:00:05  lr: 0.000500  loss: 0.2077 (0.1875)  loss_classifier: 0.0284 (0.0264)  loss_box_reg: 0.0428 (0.0391)  loss_mask: 0.1200 (0.1182)  loss_objectness: 0.0004 (0.0008)  loss_rpn_box_reg: 0.0032 (0.0031)  time: 0.5849  data: 0.0097  max mem: 3409\n",
            "Epoch: [4]  [59/60]  eta: 0:00:00  lr: 0.000500  loss: 0.2077 (0.1882)  loss_classifier: 0.0283 (0.0266)  loss_box_reg: 0.0428 (0.0393)  loss_mask: 0.1285 (0.1184)  loss_objectness: 0.0007 (0.0008)  loss_rpn_box_reg: 0.0032 (0.0030)  time: 0.5709  data: 0.0085  max mem: 3409\n",
            "Epoch: [4] Total time: 0:00:34 (0.5752 s / it)\n",
            "creating index...\n",
            "index created!\n",
            "Test:  [ 0/50]  eta: 0:00:26  model_time: 0.2368 (0.2368)  evaluator_time: 0.0050 (0.0050)  time: 0.5327  data: 0.2896  max mem: 3409\n",
            "Test:  [49/50]  eta: 0:00:00  model_time: 0.1164 (0.1201)  evaluator_time: 0.0034 (0.0050)  time: 0.1271  data: 0.0043  max mem: 3409\n",
            "Test: Total time: 0:00:07 (0.1435 s / it)\n",
            "Averaged stats: model_time: 0.1164 (0.1201)  evaluator_time: 0.0034 (0.0050)\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.822\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.984\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.950\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.398\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.650\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.849\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.354\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.860\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.860\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.500\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.764\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.882\n",
            "IoU metric: segm\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.794\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.984\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.956\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.428\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.489\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.816\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.334\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.826\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.826\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.600\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.771\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.838\n",
            "That's it!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image = read_image(\"tv_image05.png\")\n",
        "eval_transform = get_transform(train=False)\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    x = eval_transform(image)\n",
        "    # convert RGBA -> RGB and move to device\n",
        "    x = x[:3, ...].to(device)\n",
        "    predictions = model([x, ])\n",
        "    pred = predictions[0]\n",
        "\n",
        "image = (255.0 * (image - image.min()) / (image.max() - image.min())).to(torch.uint8)\n",
        "image = image[:3, ...]\n",
        "pred_labels = [f\"pedestrian: {score:.3f}\" for label, score in zip(pred[\"labels\"], pred[\"scores\"])]\n",
        "pred_boxes = pred[\"boxes\"].long()\n",
        "output_image = draw_bounding_boxes(image, pred_boxes, pred_labels, colors=\"red\")\n",
        "\n",
        "masks = (pred[\"masks\"] > 0.7).squeeze(1)\n",
        "output_image = draw_segmentation_masks(output_image, masks, alpha=0.5, colors=\"blue\")\n",
        "\n",
        "plt.figure(figsize=(12, 12))\n",
        "plt.imshow(output_image.permute(1, 2, 0))"
      ],
      "metadata": {
        "id": "e0NeTKKLZqOS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LrO-MZ1I9p8c"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}